+++
author = "Soeun"
title = "Nvidia Triton Server ì—ì„œ ëª¨ë¸ ë°°í¬í•˜ê¸°"
date = "2023-08-20"
summary = "ì‚½ì§ˆì„ í†µí•´ í—¤ì³ë‚˜ê°„ Triton Server ì‚¬ìš©ê¸° - 1íƒ„"
categories = [
    "CS"
]
tags = [
    "Triton",
]
slug = "model-deploy"
series = ["Triton Inference Server"]
series_order = 1
+++

## Part1. model deployment

ìš°ì„ , https://github.com/triton-inference-server/tutorials/tree/main ë¥¼ git clone í•´ì•¼ í•©ë‹ˆë‹¤. (ìš©ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ main ë¸Œëœì¹˜ë§Œ clone í–ˆìŠµë‹ˆë‹¤.)

ì €ëŠ” Nvidia Driver ê°€ ì—†ëŠ” ë§¥ë¶ì„ ì‚¬ìš©ì¤‘ì´ë¯€ë¡œ, AWS ìƒì—ì„œ GPU ê°€ ìˆëŠ” EC2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ì´ë•Œ, Tutorial ì—ì„œëŠ” `nvcr.io/nvidia/tritonserver:<xx.yy>` ë¡œ ë²„ì „ì„ ì§ì ‘ ê³ ë¥¼ ìˆ˜ ìˆëŠ”ë°, `nvidia-smi` ë¡œ ë³¸ì¸ì˜ cuda ë²„ì „ì„ í™•ì¸í•œ í›„ í˜¸í™˜ ë˜ëŠ” triton server ë²„ì „ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. (ì´ê²ƒ ë•Œë¬¸ì— 3ì‹œê°„ ë™ì•ˆ ì‚½ì§ˆí–ˆìŠµë‹ˆë‹¤..)

```sh
docker run --gpus=all -it --shm-size=256m --rm -p8000:8000 -p8001:8001 -p8002:8002 -v $(pwd)/model_repository:/models nvcr.io/nvidia/tritonserver:23.09-py3
```

ì €ëŠ” nvidia-smi ì˜ cuda ë²„ì „ (12.2) ì™€ í˜¸í™˜ë˜ëŠ” tritonserver ì˜ 23.09 ë²„ì „ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

![image](https://github.com/ddoddii/ddoddii.github.io/assets/95014836/cb5d3056-73cb-45c6-a7b5-47b443d5dce5)

íŠœí† ë¦¬ì–¼ì—ì„œëŠ” [EAST](https://arxiv.org/pdf/1704.03155v2.pdf)Â model ì„ ì‚¬ìš©í•˜ì—¬, ì‚¬ì§„ ì† ë¬¸ìë¥¼ ì¸ì‹í•˜ëŠ” ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

EC2 ìƒ, í˜¹ì€ ë³¸ì¸ì˜ ì»´í“¨í„°ì— GPU ê°€ ìˆë‹¤ë©´ ë¡œì»¬ì—ì„œ git clone ì„ í•œ í›„

```sh
cd Conceptual_Guide/Part_1-model_deployment
```

### Model 1 : Text Detection

OpenCV's EAST model ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  unzip í•©ë‹ˆë‹¤.

```sh
wget https://www.dropbox.com/s/r2ingd0l3zt8hxs/frozen_east_text_detection.tar.gz
tar -xvf frozen_east_text_detection.tar.gz
```

tf2onnx ë¥¼ ì„¤ì¹˜í•œ í›„ onnx ëª¨ë¸ë¡œ export í•´ì¤ë‹ˆë‹¤.

```sh
pip install -U tf2onnx
python -m tf2onnx.convert --input frozen_east_text_detection.pb --inputs "input_images:0" --outputs "feature_fusion/Conv_7/Sigmoid:0","feature_fusion/concat_3:0" --output detection.onnx
```

### Model 2 : Text Recognition

Text Recognition model weights ë¥¼ ë‹¤ìš´ë¡œë“œ í•©ë‹ˆë‹¤.

```
wget https://www.dropbox.com/sh/j3xmli4di1zuv3s/AABzCC1KGbIRe2wRwa3diWKwa/None-ResNet-None-CTC.pth
```

ì•„ë˜ì˜ script ë¥¼ ë³µì‚¬í•œ í›„, convert.py íŒŒì¼ì„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ê·¸ í›„ `python convert.py` ë¥¼ ì‹¤í–‰í•˜ë©´ onnx ëª¨ë¸ íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤.

```python
import torch
from utils.model import STRModel

# Create PyTorch Model Object
model = STRModel(input_channels=1, output_channels=512, num_classes=37)

# Load model weights from external file
state = torch.load("None-ResNet-None-CTC.pth")
state = {key.replace("module.", ""): value for key, value in state.items()}
model.load_state_dict(state)

# Create ONNX file by tracing model
trace_input = torch.randn(1, 1, 32, 100)
torch.onnx.export(model, trace_input, "str.onnx", verbose=True)
```

ëª¨ë¸ ë ˆí¬ êµ¬ì¡°ì— íŠ¹ë³„í•œ ê·œì¹™ì´ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ì™€ ê°™ì€ êµ¬ì¡°ë¡œ ë ˆí¬ê°€ ë˜ì–´ì•¼ Triton Inference Server ê°€ ì¸ì‹í•©ë‹ˆë‹¤.

```
# Example repository structure
<model-repository>/
  <model-name>/
    [config.pbtxt]
    [<output-labels-file> ...]
    <version>/
      <model-definition-file>
    <version>/
      <model-definition-file>
    ...
  <model-name>/
    [config.pbtxt]
    [<output-labels-file> ...]
    <version>/
      <model-definition-file>
    <version>/
      <model-definition-file>
    ...
  ...
```

- `model-name` : ëª¨ë¸ì˜ ì‹ë³„ ì´ë¦„
- `config.pbtxt` : ê° ëª¨ë¸ì— ëŒ€í•´ ì‚¬ìš©ìëŠ” ëª¨ë¸ êµ¬ì„±ì„ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ êµ¬ì„±ì€ ìµœì†Œí•œ ëª¨ë¸ ì…ë ¥ê³¼ ì¶œë ¥ì˜ ë°±ì—”ë“œ, ì´ë¦„, ëª¨ì–‘ ë° ë°ì´í„° ìœ í˜•ì„ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤. ì¼ë°˜ì ì¸ ë°±ì—”ë“œì˜ ëŒ€ë¶€ë¶„ì—ì„œ ì´ êµ¬ì„± íŒŒì¼ì€ ê¸°ë³¸ê°’ìœ¼ë¡œ ìë™ ìƒì„±ë©ë‹ˆë‹¤. êµ¬ì„± íŒŒì¼ì˜ ì „ì²´ ì‚¬ì–‘ì€ model_config protobuf ì •ì˜ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- `version` : ë™ì¼í•œ ëª¨ë¸ì— ëŒ€í•´ ì—¬ëŸ¬ ë²„ì „ì„ ì •ì˜í•˜ê³ , ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ì•„ë˜ì˜ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ì—¬ ìœ„ì™€ ê°™ì€ êµ¬ì¡°ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```sh
mkdir -p model_repository/text_detection/1
mv detection.onnx model_repository/text_detection/1/model.onnx

mkdir -p model_repository/text_recognition/1
mv str.onnx model_repository/text_recognition/1/model.onnx
```

ê·¸ë ‡ë‹¤ë©´ ìš°ë¦¬ì˜ ë ˆí¬ëŠ” ì•„ë˜ì™€ ê°™ì´ ìƒê²¨ì•¼ í•©ë‹ˆë‹¤.

```
# Expected folder layout
model_repository/
â”œâ”€â”€ text_detection
â”‚   â”œâ”€â”€ 1
â”‚   â”‚   â””â”€â”€ model.onnx
â”‚   â””â”€â”€ config.pbtxt
â””â”€â”€ text_recognition
    â”œâ”€â”€ 1
    â”‚   â””â”€â”€ model.onnx
    â””â”€â”€ config.pbtxt
```

### Launching the server

docker ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œë²„ë¥¼ ëŸ°ì¹­í•©ë‹ˆë‹¤. ì €ëŠ” 23.09 ë²„ì „ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

```sh
# Replace the yy.mm in the image name with the release year and month
# of the Triton version needed, eg. 22.08

docker run --gpus=all -it --shm-size=256m --rm -p8000:8000 -p8001:8001 -p8002:8002 -v $(pwd)/model_repository:/models nvcr.io/nvidia/tritonserver:<yy.mm>-py3
```

ê·¸ ë‹¤ìŒ, ì•„ë˜ì™€ ê°™ì€ ì°½ì´ ëœ¨ë©´ ì„±ê³µì…ë‹ˆë‹¤ ğŸ‘

<img width="700" alt="image" src="https://github.com/ddoddii/ddoddii.github.io/assets/95014836/44b50d9f-18c7-4f3b-b8af-e28a40880d05">

ì»¨í…Œì´ë„ˆ ì•ˆì— ë“¤ì–´ì™”ìœ¼ë©´, triton server ë¥¼ ëŸ°ì¹­í•©ë‹ˆë‹¤.

```sh
tritonserver --model-repository=/models
```

ì„±ê³µì ì´ë¼ë©´, ì•„ë˜ì™€ ê°™ì´ ëª¨ë¸ë“¤ì´ ëª¨ë‘ READY ìƒíƒœì—¬ì•¼ í•©ë‹ˆë‹¤.
![image](https://github.com/ddoddii/ddoddii.github.io/assets/95014836/32eecadb-6963-497f-96f8-6723bdc193da)

ì´ì œ ì„œë²„ë¥¼ ëŸ°ì¹­í–ˆìœ¼ë‹ˆ, ìš”ì²­ì„ ë³´ë‚¼ client ìª½ì„ ë§Œë“¤ì–´ ë´…ì‹œë‹¤.

### Building a client application

Triton Inference Server ì— ë©”ì‹œì§€ë¥¼ ë³´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Triton Inference Server ì™€ ìƒí˜¸ ì‘ìš©í•˜ëŠ” ë°©ë²•ì€ ì„¸ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤:

- HTTP(S) API
- gRPC API
- Native C API

ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” `client.py` íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ HTTP API ë¥¼ ì´ìš©í•´ ì†Œí†µí•´ë´…ì‹œë‹¤. Â `tritonclient` ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” HTTP ìš”ì²­ì„ ë³´ë‚¼ ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.

ì„œë²„ì™€ ë‹¤ë¥¸ í„°ë¯¸ë„ ì°½ì„ ì—´ê³ , ì ‘ì†í•œ ë‹¤ìŒ ì•„ë˜ë¥¼ ì…ë ¥í•©ì‹œë‹¤.

```sh
pip install tritonclient[http] opencv-python-headless
python client.py
```

ìš°ì„  img1.jpg ê°€ ì²˜ë¦¬ë  ê²ƒì…ë‹ˆë‹¤. ì €ëŠ” ì—¬ê¸°ì— ì‹¤í—˜ì„ ìœ„í•´ go ê°€ ì í˜€ì§„ í‘œì§€íŒ ì‚¬ì§„ë„ ì¶”ë¡ ì— ì´ìš©í•´ ë³´ì•˜ìŠµë‹ˆë‹¤. ì²˜ìŒ ìš”ì²­í•  ë•ŒëŠ” ì¢€ ì‹œê°„ì´ ê±¸ë¦¬ì§€ë§Œ, í•œë²ˆ ì—°ê²°ì„ í•´ë†“ìœ¼ë©´ ì¶”ë¡  ì†ë„ê°€ êµ‰ì¥íˆ ë¹ ë¥¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- ì²«ë²ˆì§¸ ìš”ì²­ (go í‘œì§€íŒ ì´ë¯¸ì§€)

![image](https://github.com/ddoddii/ddoddii.github.io/assets/95014836/87ef5e6e-0678-4a78-ab58-5557b9c0bc19)

- ì´í›„ ìš”ì²­ (stop sign ì´ë¯¸ì§€)

![image](https://github.com/ddoddii/ddoddii.github.io/assets/95014836/8e351ba8-b3b5-4ee8-9049-028530497c0a)

ë¬´ë ¤ 0.22 ì´ˆ ë§Œì— ì‚¬ì§„ì„ ì¸ì‹í•˜ê³ , text_detectionê³¼ text_recognition ì‘ì—…ì„ ëª¨ë‘ í•´ëƒˆìŠµë‹ˆë‹¤.

## Reference

- https://github.com/triton-inference-server/tutorials
